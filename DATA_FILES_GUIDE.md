# Data Files Guide

## 📊 Current Active Data Files

The project uses **5 main CSV files** located in the `data/` directory. These are generated by `complete_analysis.py` and used by the Jupyter notebook.

### ✅ Active Files (Used in Analysis)

| File | Size | Records | Description | Used By |
|------|------|---------|-------------|---------|
| **transactions.csv** | 6.3 MB | 50,000 | Complete transaction records with revenue, costs, margins | All analyses, ML models |
| **customers.csv** | 940 KB | 15,000 | Customer demographics and profiles | Customer behavior analysis, CLV model |
| **stores.csv** | 12 KB | 120 | Store locations and infrastructure data | Regional analysis, store risk model |
| **products.csv** | 2.5 KB | 39 | Product catalog with pricing and categories | Category analysis |
| **inventory.csv** | 219 KB | 4,467 | Store-level inventory and stockout tracking | Supply chain analysis |

---

## 🗑️ Old/Deprecated Files

The following files were from earlier iterations and are **NOT used** in the current analysis:

- ~~`simulated_transactions.csv`~~ - Old version (replaced by `transactions.csv`)
- ~~`simulated_products.csv`~~ - Old version (replaced by `products.csv`)
- ~~`simulated_stores.csv`~~ - Old version (replaced by `stores.csv`)

**These files are excluded via `.gitignore` and should be deleted if found.**

---

## 📝 Data Schema

### transactions.csv
```
transaction_id, transaction_date, customer_id, product_id, store_id, region_tier,
quantity, unit_price, revenue, product_cost, logistics_cost, spoilage_cost,
total_cost, margin, margin_pct, discount_pct, delivery_time_hours,
delivery_distance_km, payment_method, is_perishable
```

### customers.csv
```
customer_id, primary_store_id, region_tier, age, income_bracket,
digital_literacy_score, registration_date
```

### stores.csv
```
store_id, store_name, region_tier, city, state, city_population,
infrastructure_score, warehouse_distance_km, opening_date
```

### products.csv
```
product_id, product_name, category, unit_cost, list_price,
target_margin_pct, is_perishable, avg_shelf_life_days
```

### inventory.csv
```
inventory_id, store_id, product_id, current_stock, reorder_point,
stockout_days_last_month, avg_daily_sales, last_restock_date
```

---

## 🔄 Data Generation

All data is generated by running:
```bash
python3 complete_analysis.py
```

This script:
1. Generates realistic simulated data for Indian retail market
2. Creates tier-specific business patterns (Metro vs Tier 2/3)
3. Calculates derived metrics (margins, costs, etc.)
4. Saves all 5 CSV files to `data/` directory
5. Generates 8 visualizations in `images/` directory

**Runtime:** 3-5 minutes

---

## 📊 Data Usage in Analysis

### Jupyter Notebook (`new_final_JIOmart_expansion_analysis.ipynb`)
- **Loads:** All 5 CSV files
- **Primary Analysis:** transactions.csv (joins with others)
- **ML Models:** 
  - Random Forest: Uses store-aggregated transaction data
  - Gradient Boosting: Uses customer behavior data
  - K-Means: Uses customer features

### SQL Queries (`sql_scripts/analytics_queries.sql`)
- Designed for all 5 tables
- 13 pre-built queries for business intelligence
- Can be used if data is loaded into PostgreSQL/MySQL

---

## ✅ Data Quality

- **No missing values** in key fields
- **Realistic patterns** by region tier
- **Referential integrity** maintained (all foreign keys valid)
- **Date range:** Jan 2023 - Sep 2024
- **Seed:** 42 (reproducible results)

---

## 🔍 Quick Verification

Check if all required files exist:
```bash
ls -lh data/*.csv
```

Expected output:
```
customers.csv     (940 KB)
inventory.csv     (219 KB)
products.csv      (2.5 KB)
stores.csv        (12 KB)
transactions.csv  (6.3 MB)
```

Total: **~8 MB** of data

---

## 🚀 Usage

### Option 1: Python Script
```python
import pandas as pd

# Load data
transactions = pd.read_csv('data/transactions.csv')
customers = pd.read_csv('data/customers.csv')
stores = pd.read_csv('data/stores.csv')
products = pd.read_csv('data/products.csv')
inventory = pd.read_csv('data/inventory.csv')
```

### Option 2: Jupyter Notebook
Open `new_final_JIOmart_expansion_analysis.ipynb` and run all cells. Data loading is in Section 2.

---

## 📌 Summary

- ✅ **5 active files** - All in `data/` directory
- ❌ **0 duplicate files** - Old "simulated_*.csv" files removed
- 📊 **50K+ transactions** - Comprehensive dataset
- 🎯 **100% utilized** - Every file is used in analysis

All data files are properly tracked in Git and pushed to the repository.
